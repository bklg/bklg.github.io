<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Use co-occurrence to discover region-word pairs from image-text pairs for open-vocabulary object detection pre-training.">
  <meta name="keywords" content="CoDet, Co-occurrence, Open-vocabulary Detection">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Recognize Any Regions</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
<!--  <link rel="icon" href="./static/images/favicon.svg">-->

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!--<nav class="navbar" role="navigation" aria-label="main navigation">-->
<!--  <div class="navbar-brand">-->
<!--    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--      <span aria-hidden="true"></span>-->
<!--    </a>-->
<!--  </div>-->
<!--  <div class="navbar-menu">-->
<!--    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">-->
<!--      <a class="navbar-item" href="https://keunhong.com">-->
<!--      <span class="icon">-->
<!--          <i class="fas fa-home"></i>-->
<!--      </span>-->
<!--      </a>-->

<!--      <div class="navbar-item has-dropdown is-hoverable">-->
<!--        <a class="navbar-link">-->
<!--          More Research-->
<!--        </a>-->
<!--        <div class="navbar-dropdown">-->
<!--          <a class="navbar-item" href="https://hypernerf.github.io">-->
<!--            HyperNeRF-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://nerfies.github.io">-->
<!--            Nerfies-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://latentfusion.github.io">-->
<!--            LatentFusion-->
<!--          </a>-->
<!--          <a class="navbar-item" href="https://photoshape.github.io">-->
<!--            PhotoShape-->
<!--          </a>-->
<!--        </div>-->
<!--      </div>-->
<!--    </div>-->

<!--  </div>-->
<!--</nav>-->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-3 publication-title">Recognize Any Regions</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              Haosen Yang<sup>1,2</sup>,</span>
            <span class="author-block">
              Chuofan Ma<sup>3</sup>,</span>
            <span class="author-block">
              Bin Wen<sup>2</sup>,
            </span>
            <span class="author-block">
              Yi Jiang<sup>2</sup>,
            </span>
            <span class="author-block">
              Zehuan Yuan<sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://xjqi.github.io/">Xiatian Zhu</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Surrey,</span>
            <span class="author-block"><sup>2</sup>ByteDance,</span>
            <span class="author-block"><sup>3</sup>University of Hong Kong</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://arxiv.org/pdf/2011.12948"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fas fa-file-pdf"></i>-->
<!--                  </span>-->
<!--                  <span>Paper</span>-->
<!--                </a>-->
<!--              </span>-->
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2311.01373.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="fab fa-youtube"></i>-->
<!--                  </span>-->
<!--                  <span>Video</span>-->
<!--                </a>-->
<!--              </span>-->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/Surrey-UPLab/Recognize-Any-Regions"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/spaces/bklg/RegionSpot"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Demo</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
<!--              <span class="link-block">-->
<!--                <a href="https://github.com/google/nerfies/releases/tag/0.1"-->
<!--                   class="external-link button is-normal is-rounded is-dark">-->
<!--                  <span class="icon">-->
<!--                      <i class="far fa-images"></i>-->
<!--                  </span>-->
<!--                  <span>Data</span>-->
<!--                </a>-->
<!--              </span>  -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/illust.png" alt="Teaser image."/>
      <h2 class="subtitle has-text-centered">
         Illustration of typical region-level visual understanding architecture.
      </h2>
    </div>
  </div>
</section>

<!-- <section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-fullwidth">
        <h2 class="title is-3">Breaking the Chicken-and-Egg Problem</h2>
        <img src="static/images/meme.png"/>
        <div class="content has-text-justified">
          <p>
            Previous studies typically rely on region-text similarity to discover pseudo region-text pairs from image-text pairs.
            But a tricky thing is that, to get accurate similarity estimation, you need a region-level aligned vision-language sapce,
            which in turn requires abundant region-text pairs to train.
            <br><br>
            To break the chicken-and-egg problem, we introduce co-occurrence based region-word alignment,
            which solely relies on region-region similarity to discover pseudo region-text pairs.
            A nice property of co-occurrence is that you only need to scale up visual pre-training to get higher-quality pseudo-labels.
          </p>
        </div>
      </div>
    </div>
  </div>
</section> -->

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            nderstanding the semantics of individual regions or patches within unconstrained images, such as in open-world object detection, represents a critical yet
            challenging task in computer vision. Building on the success of powerful image level vision-language (ViL) foundation models like CLIP, recent efforts have
            sought to harness their capabilities by either training a contrastive model fromscratch with an extensive collection of region-label pairs or aligning the 
            outputs of a detection model with image-level representations of region proposals. Despite notable progress, these approaches are plagued by computationally 
            intensive training requirements, susceptibility to data noise, and deficiency in contextual information. To address these limitations, we explore the 
            synergistic potential of off-the-shelf foundation models, leveraging their respective strengths in localiztion and semantics. We introduce a novel, generic, 
            and efficient region recognition architecture, named RegionSpot, designed to integrate position-aware localization knowledge from a localization foundation 
            model (e.g., SAM) with semantic information extracted from a ViL model (e.g., CLIP). To fully exploit pretrained knowledge while minimizing training overhead, 
            we keep both foundation models frozen, focusing optimization efforts solely on a lightweight attention-based knowledge integration module. Through extensive 
            experiments in the context of open-world object recognition, our RegionSpot demonstrates significant performance improvements over prior alternatives, while 
            also providing substantial computational savings. For instance, training our model with 3 million data in a single day using 8 V100 GPUs. Our model outperforms 
            GLIP by 6.5% in mean average precision (mAP), with an even larger margin by 14.8% for more challenging and rare categories.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Main Figure. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
<!--        <h2 class="title is-3">Method</h2>-->
        <img src="./static/images/framework.jpg" />
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-fullwidth">
        <h2 class="title is-3">Example Result</h2>
        <img src="static/images/results.jpg"/>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Benchmark Results</h2>
        <img src="./static/images/table.png"/>
      </div>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@inproceedings{RegionSpot,
    title={Recognize Any Regions},
    author={Yang, Haosen and Ma, Chuofan and Wen, Bin and Jiang, Yi and Yuan, Zehuan and Zhu, Xiatian},
    journal={arXiv preprint arXiv:2311.01373},
    year={2023}
  }
}</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
<!--    <div class="content has-text-centered">-->
<!--      <a class="icon-link"-->
<!--         href="./static/videos/nerfies_paper.pdf">-->
<!--        <i class="fas fa-file-pdf"></i>-->
<!--      </a>-->
<!--      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>-->
<!--        <i class="fab fa-github"></i>-->
<!--      </a>-->
<!--    </div>-->
    <div class="columns is-centered">
      <a href="https://github.com/nerfies/nerfies.github.io">Website template</a>
<!--      <div class="column is-8">-->
<!--        <div class="content">-->
<!--          <p>-->
<!--            This website is licensed under a <a rel="license"-->
<!--                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative-->
<!--            Commons Attribution-ShareAlike 4.0 International License</a>.-->
<!--          </p>-->
<!--          <p>-->
<!--            This means you are free to borrow the <a-->
<!--              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,-->
<!--            we just ask that you link back to this page in the footer.-->
<!--            Please remember to remove the analytics code included in the header of the website which-->
<!--            you do not want on your website.-->
<!--          </p>-->
<!--        </div>-->
      </div>
    </div>
  </div>
</footer>

</body>
</html>
